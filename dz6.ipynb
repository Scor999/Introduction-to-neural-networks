{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Scor999/Introduction-to-neural-networks/blob/main/dz6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, Conv2DTranspose\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n"
      ],
      "metadata": {
        "id": "TdJdbFRGcQW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка и предобработка данных\n",
        "def download_data(path):\n",
        "    data = []\n",
        "    for path_image in sorted(os.listdir(path=path)):\n",
        "        image = Image.open(path + path_image) # Открываем изображение.\n",
        "        data.append(np.array(image)) # Загружаем пиксели.\n",
        "    return data\n",
        "\n",
        "def resize(input_image, input_mask):\n",
        "    input_image = tf.image.resize(input_image, (128, 128), method=\"nearest\")\n",
        "    input_mask = tf.image.resize(input_mask, (128, 128), method=\"nearest\")\n",
        "    return input_image, input_mask"
      ],
      "metadata": {
        "id": "yk_1vhc3cT0v"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = download_data(r\"train/images/\")\n",
        "Y_train = download_data(r\"train/masks/\")\n",
        "X_test = download_data(r\"test/images/\")\n",
        "Y_test = download_data(r\"test/masks/\")\n"
      ],
      "metadata": {
        "id": "vf2LxGrkcX1e"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = resize(X_train, Y_train)\n",
        "X_test, Y_test = resize(X_test, Y_test)"
      ],
      "metadata": {
        "id": "YGdx8qwwcXvv"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение палитры цветов\n",
        "palette = {\n",
        "    (60, 16, 152): 0,    # Building\n",
        "    (132, 41, 246): 1,   # Land\n",
        "    (110, 193, 228): 2,  # Road\n",
        "    (254, 221, 58): 3,   # Vegetation\n",
        "    (226, 169, 41): 4,   # Water\n",
        "    (155, 155, 155): 5   # Unlabeled\n",
        "}"
      ],
      "metadata": {
        "id": "DmyipS50cg9u"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Инвертированная палитра\n",
        "invert_palette = {v: k for k, v in palette.items()}\n",
        "\n",
        "def convert_from_color(arr_3d, palette=invert_palette):\n",
        "    \"\"\" RGB-color encoding to grayscale labels \"\"\"\n",
        "    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.int8)\n",
        "    for c, i in palette.items():\n",
        "        m = np.all(arr_3d == np.array(c).reshape(1, 1, 3), axis=2)\n",
        "        arr_2d[m] = i\n",
        "\n",
        "    arr_2d = arr_2d.tolist()\n",
        "    for i in range(len(arr_2d)):\n",
        "        for j in range(len(arr_2d[0])):\n",
        "            label = [0, 0, 0, 0, 0, 0]\n",
        "            label[arr_2d[i][j]] = 1\n",
        "            arr_2d[i][j] = label\n",
        "    arr_2d = np.array(arr_2d)\n",
        "\n",
        "    return arr_2d"
      ],
      "metadata": {
        "id": "W8enk3fWcjQm"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Преобразование меток данных в one-hot encoded формат с использованием палитры цветов\n",
        "Y_train_pred = []\n",
        "for i in range(len(Y_train)):\n",
        "    Y_train_pred.append(convert_from_color(Y_train[i][:, :, :3], palette))\n",
        "Y_train_pred = np.array(Y_train_pred)\n",
        "\n",
        "Y_test_pred = []\n",
        "for i in range(len(Y_test)):\n",
        "    Y_test_pred.append(convert_from_color(Y_test[i][:, :, :3], palette))\n",
        "Y_test_pred = np.array(Y_test_pred)"
      ],
      "metadata": {
        "id": "Z68IJOAkcnUe"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение U-Net модели\n",
        "def conv_block(inputs, filters, kernel_size=(3, 3), activation='relu', padding='same'):\n",
        "    conv = Conv2D(filters, kernel_size, activation=activation, padding=padding)(inputs)\n",
        "    conv = Conv2D(filters, kernel_size, activation=activation, padding=padding)(conv)\n",
        "    return conv"
      ],
      "metadata": {
        "id": "Fvq65zWIcp-O"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_unet_model(input_shape, num_classes):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = conv_block(inputs, 64)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = conv_block(pool1, 128)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = conv_block(pool2, 256)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = conv_block(pool3, 512)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = conv_block(pool4, 1024)\n",
        "\n",
        "    # Decoder\n",
        "    up6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(conv5)\n",
        "    up6 = concatenate([up6, conv4], axis=3)\n",
        "    conv6 = conv_block(up6, 512)\n",
        "\n",
        "    up7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
        "    up7 = concatenate([up7, conv3], axis=3)\n",
        "    conv7 = conv_block(up7, 256)\n",
        "\n",
        "    up8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
        "    up8 = concatenate([up8, conv2], axis=3)\n",
        "    conv8 = conv_block(up8, 128)\n",
        "\n",
        "    up9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
        "    up9 = concatenate([up9, conv1], axis=3)\n",
        "    conv9 = conv_block(up9, 64)\n",
        "\n",
        "    outputs = Conv2D(num_classes, (1, 1), activation='softmax')(conv9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model"
      ],
      "metadata": {
        "id": "Q5i0fKJDctVe"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение архитектуры модели и компиляция\n",
        "input_shape = (128, 128, 3)\n",
        "num_classes = 6  # Предполагается 6 классов для сегментации\n",
        "\n",
        "unet_model = build_unet_model(input_shape, num_classes)\n",
        "unet_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "LdeN5gABcwO2"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение модели\n",
        "history = unet_model.fit(np.array(X_train)/255, Y_train_pred, epochs=5, validation_data=(np.array(X_test)/255, Y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ILixCRvc0Be",
        "outputId": "94711d96-5462-4e24-c66d-91fe49a753a6"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 12s 12s/step - loss: 1.1047 - accuracy: 0.6007 - val_loss: 1.1037 - val_accuracy: 0.5855\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 13s 13s/step - loss: 1.0986 - accuracy: 0.6007 - val_loss: 1.1002 - val_accuracy: 0.5855\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 12s 12s/step - loss: 1.0819 - accuracy: 0.6007 - val_loss: 1.0967 - val_accuracy: 0.5855\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 12s 12s/step - loss: 1.0638 - accuracy: 0.6007 - val_loss: 1.0990 - val_accuracy: 0.5855\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 12s 12s/step - loss: 1.0543 - accuracy: 0.6007 - val_loss: 1.1096 - val_accuracy: 0.5855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = unet_model.predict(X_test_pred, batch_size=1)\n",
        "\n",
        "I = 0 # номер картинки после обработки нейронной сетью\n",
        "plt.imshow(np.array(X_test)[I])\n",
        "plt.show()\n",
        "plt.imshow(np.array(Y_test)[I])\n",
        "plt.show()\n",
        "plt.imshow(convert_to_color(np.argmax(out[I], axis=-1)))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vLdJi29gdp1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import SGD\n",
        "\n",
        "# Определение архитектуры модели и компиляция\n",
        "input_shape = (128, 128, 3)\n",
        "num_classes = 6  # Предполагается 6 классов для сегментации\n",
        "\n",
        "unet_model = build_unet_model(input_shape, num_classes)\n",
        "\n",
        "# Использование оптимизатора SGD с параметрами по умолчанию\n",
        "optimizer = SGD(lr=0.01, momentum=0.9)  # Установка скорости обучения и параметра момента\n",
        "\n",
        "unet_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Обучение модели\n",
        "history = unet_model.fit(np.array(X_train)/255, Y_train_pred, epochs=10, validation_data=(np.array(X_test)/255, Y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cTSzKgFo-ob",
        "outputId": "2c6710c3-534f-46ef-d95e-eb2c87475a0e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 15s 15s/step - loss: 1.7873 - accuracy: 0.0253 - val_loss: 1.7704 - val_accuracy: 0.1935\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 11s 11s/step - loss: 1.7681 - accuracy: 0.1988 - val_loss: 1.7338 - val_accuracy: 0.5722\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 12s 12s/step - loss: 1.7315 - accuracy: 0.5843 - val_loss: 1.6910 - val_accuracy: 0.5854\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 12s 12s/step - loss: 1.6885 - accuracy: 0.6007 - val_loss: 1.6450 - val_accuracy: 0.5855\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 12s 12s/step - loss: 1.6422 - accuracy: 0.6007 - val_loss: 1.5787 - val_accuracy: 0.5855\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 12s 12s/step - loss: 1.5755 - accuracy: 0.6007 - val_loss: 1.4885 - val_accuracy: 0.5855\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 12s 12s/step - loss: 1.4853 - accuracy: 0.6007 - val_loss: 1.3756 - val_accuracy: 0.5855\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 12s 12s/step - loss: 1.3739 - accuracy: 0.6007 - val_loss: 1.2507 - val_accuracy: 0.5855\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 12s 12s/step - loss: 1.2544 - accuracy: 0.6007 - val_loss: 1.1705 - val_accuracy: 0.5855\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 12s 12s/step - loss: 1.1876 - accuracy: 0.6007 - val_loss: 1.1927 - val_accuracy: 0.5855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adagrad\n",
        "\n",
        "# Определение архитектуры модели и компиляция\n",
        "input_shape = (128, 128, 3)\n",
        "num_classes = 6  # Предполагается 6 классов для сегментации\n",
        "\n",
        "unet_model = build_unet_model(input_shape, num_classes)\n",
        "\n",
        "# Использование оптимизатора Adagrad с параметром скорости обучения lr=0.01\n",
        "optimizer = Adagrad(lr=0.01)\n",
        "\n",
        "unet_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Обучение модели\n",
        "history = unet_model.fit(np.array(X_train)/255, Y_train_pred, epochs=10, validation_data=(np.array(X_test)/255, Y_test_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X11Dh9Xuqx1c",
        "outputId": "895cf846-4214-439d-86fb-74b094f195ff"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adagrad.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 15s 15s/step - loss: 1.7664 - accuracy: 0.5758 - val_loss: 1.7568 - val_accuracy: 0.5813\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 12s 12s/step - loss: 1.7586 - accuracy: 0.5944 - val_loss: 1.7493 - val_accuracy: 0.5847\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 12s 12s/step - loss: 1.7510 - accuracy: 0.5991 - val_loss: 1.7421 - val_accuracy: 0.5854\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 12s 12s/step - loss: 1.7437 - accuracy: 0.6003 - val_loss: 1.7353 - val_accuracy: 0.5856\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 12s 12s/step - loss: 1.7368 - accuracy: 0.6007 - val_loss: 1.7287 - val_accuracy: 0.5856\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 12s 12s/step - loss: 1.7302 - accuracy: 0.6008 - val_loss: 1.7223 - val_accuracy: 0.5855\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 12s 12s/step - loss: 1.7237 - accuracy: 0.6007 - val_loss: 1.7159 - val_accuracy: 0.5855\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 11s 11s/step - loss: 1.7172 - accuracy: 0.6008 - val_loss: 1.7095 - val_accuracy: 0.5855\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 11s 11s/step - loss: 1.7106 - accuracy: 0.6008 - val_loss: 1.7028 - val_accuracy: 0.5855\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 12s 12s/step - loss: 1.7038 - accuracy: 0.6008 - val_loss: 1.6959 - val_accuracy: 0.5855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Вывод\n",
        "\n",
        "На ималых данных удалось добиться только val_accuracy: 0.5855. При изменении оптимизаторов нет существенных изменеий."
      ],
      "metadata": {
        "id": "C22a_f1osnul"
      }
    }
  ]
}