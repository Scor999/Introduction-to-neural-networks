{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNovrnelu+Fw+e/vxlk4HAi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Scor999/Introduction-to-neural-networks/blob/main/dz4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вы — лучший ответ на проблемы, которые возникли в понедельник.\n",
        "Думайте позитивно и верьте в свою способность достигать отличных результатов.\n",
        "Если вы смогли в понедельник подняться с постели, значит вы супер герой."
      ],
      "metadata": {
        "id": "seP4ZAQ_Dalt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "from keras.layers import *\n",
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "amOVc-L1DhmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train_data.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "    text = text.replace('\\ufeff', '') # убираем первый невидимый символ\n",
        "    text = re.sub(r'[^А-я ]', '', text) # убираем все недопустимые символы"
      ],
      "metadata": {
        "id": "tTWy9oPKENCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_characters = 34 #33 буквы + пробел"
      ],
      "metadata": {
        "id": "47A2oVSIEqjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=num_characters, char_level=True)"
      ],
      "metadata": {
        "id": "7ln63YDNHsuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(text)"
      ],
      "metadata": {
        "id": "FA0qfyp6Hva-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCbfC9jzHz1Y",
        "outputId": "ae597005-35b3-4519-8204-1f1ddc36c712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 1, 'о': 2, 'т': 3, 'е': 4, 'и': 5, 'в': 6, 'н': 7, 'с': 8, 'л': 9, 'п': 10, 'ь': 11, 'ы': 12, 'р': 13, 'а': 14, 'д': 15, 'у': 16, 'к': 17, 'з': 18, 'ч': 19, 'й': 20, 'м': 21, 'г': 22, 'б': 23, 'я': 24, 'ш': 25, 'ю': 26, 'х': 27}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp_chars = 6\n",
        "data = tokenizer.texts_to_matrix(text)"
      ],
      "metadata": {
        "id": "NNS1oHTiIKgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data [1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzCOUVmrIkP3",
        "outputId": "5be224e6-c535-44ea-a03e-c19effe6bb00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 394
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = data.shape[0]-inp_chars\n",
        "n  #размер обучающего множества"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-1MqTUVIwCo",
        "outputId": "9309e4b5-9f83-47a2-8e89-5ed32867e104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199"
            ]
          },
          "metadata": {},
          "execution_count": 395
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([data[i:i+inp_chars, :] for i in range(n)])\n",
        "Y = data[inp_chars:] #предсказание следующего символа"
      ],
      "metadata": {
        "id": "gIZwUV5eKmyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Input((inp_chars, num_characters)))\n",
        "model.add(SimpleRNN(500, activation='tanh'))\n",
        "model.add(Dense(num_characters, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlX9yahlK844",
        "outputId": "05a8896e-dc31-4254-d763-536a8ee0fb10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_23 (SimpleRNN)   (None, 500)               267500    \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 34)                17034     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 284534 (1.09 MB)\n",
            "Trainable params: 284534 (1.09 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "history = model.fit(X, Y, batch_size=32, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsZFSOm8LPF4",
        "outputId": "d6a446aa-b188-4648-af28-bfa3b59f3d11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 1s 23ms/step - loss: 3.4033 - accuracy: 0.0603\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 2.4608 - accuracy: 0.3216\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 1.9637 - accuracy: 0.4523\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 1.5354 - accuracy: 0.5377\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 1.2602 - accuracy: 0.6231\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 1.0141 - accuracy: 0.6985\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.8619 - accuracy: 0.7538\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.7311 - accuracy: 0.8141\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.6992 - accuracy: 0.7990\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.6066 - accuracy: 0.8392\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.6715 - accuracy: 0.8392\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.5346 - accuracy: 0.8995\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.4422 - accuracy: 0.8894\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.4407 - accuracy: 0.8945\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.4008 - accuracy: 0.8945\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.3154 - accuracy: 0.9146\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.3015 - accuracy: 0.9447\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.3827 - accuracy: 0.8995\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.3058 - accuracy: 0.9347\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2431 - accuracy: 0.9598\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.2399 - accuracy: 0.9447\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.2306 - accuracy: 0.9648\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.2841 - accuracy: 0.9246\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1982 - accuracy: 0.9648\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2558 - accuracy: 0.9598\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2434 - accuracy: 0.9598\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.2656 - accuracy: 0.9497\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1652 - accuracy: 0.9598\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1496 - accuracy: 0.9698\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1942 - accuracy: 0.9648\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.1972 - accuracy: 0.9648\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1493 - accuracy: 0.9799\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1484 - accuracy: 0.9749\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1109 - accuracy: 0.9899\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1122 - accuracy: 0.9799\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1017 - accuracy: 0.9849\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.1094 - accuracy: 0.9749\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0953 - accuracy: 0.9799\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0774 - accuracy: 0.9849\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0607 - accuracy: 0.9950\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1020 - accuracy: 0.9799\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.0784 - accuracy: 0.9899\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.0627 - accuracy: 0.9899\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.0523 - accuracy: 0.9849\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.0529 - accuracy: 0.9899\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0435 - accuracy: 0.9899\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0437 - accuracy: 0.9899\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0400 - accuracy: 0.9899\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0452 - accuracy: 0.9799\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0368 - accuracy: 0.9849\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0417 - accuracy: 0.9799\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0620 - accuracy: 0.9899\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0538 - accuracy: 0.9849\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0475 - accuracy: 0.9899\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0937 - accuracy: 0.9899\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1226 - accuracy: 0.9849\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1396 - accuracy: 0.9749\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0752 - accuracy: 0.9799\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0527 - accuracy: 0.9849\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0562 - accuracy: 0.9849\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0531 - accuracy: 0.9849\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0896 - accuracy: 0.9749\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0909 - accuracy: 0.9799\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0496 - accuracy: 0.9799\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0495 - accuracy: 0.9899\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0643 - accuracy: 0.9849\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0412 - accuracy: 0.9899\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0632 - accuracy: 0.9849\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0458 - accuracy: 0.9849\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0280 - accuracy: 0.9950\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0272 - accuracy: 0.9899\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0284 - accuracy: 0.9950\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0230 - accuracy: 0.9950\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0236 - accuracy: 0.9950\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0246 - accuracy: 0.9950\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0206 - accuracy: 0.9950\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0276 - accuracy: 0.9950\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0284 - accuracy: 0.9950\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0198 - accuracy: 0.9950\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0195 - accuracy: 0.9950\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0185 - accuracy: 0.9950\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0200 - accuracy: 0.9899\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0191 - accuracy: 0.9950\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0181 - accuracy: 0.9950\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0185 - accuracy: 0.9950\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0169 - accuracy: 0.9950\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0202 - accuracy: 0.9950\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0179 - accuracy: 0.9950\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0179 - accuracy: 0.9950\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0178 - accuracy: 0.9950\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.0182 - accuracy: 0.9899\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0171 - accuracy: 0.9899\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.0205 - accuracy: 0.9950\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.0170 - accuracy: 0.9899\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.0174 - accuracy: 0.9950\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0161 - accuracy: 0.9899\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0161 - accuracy: 0.9950\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.0171 - accuracy: 0.9950\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 51ms/step - loss: 0.0191 - accuracy: 0.9899\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 58ms/step - loss: 0.0173 - accuracy: 0.9950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def buildPhrase(inp_str, str_len = 50):\n",
        "  for i in range(str_len):\n",
        "    x = []\n",
        "    for j in range(i, i+inp_chars):\n",
        "      x.append(tokenizer.texts_to_matrix(inp_str[j])) # преобразуем символы в One-Hot-encoding\n",
        "\n",
        "    x = np.array(x)\n",
        "    inp = x.reshape(1, inp_chars, num_characters)\n",
        "\n",
        "    pred = model.predict( inp ) # предсказываем OHE четвертого символа\n",
        "    d = tokenizer.index_word[pred.argmax(axis=1)[0]] # получаем ответ в символьном представлении\n",
        "\n",
        "    inp_str += d # дописываем строку\n",
        "\n",
        "  return inp_str"
      ],
      "metadata": {
        "id": "OtcLKBoaLp-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = buildPhrase(\"утренн\")\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zWXD0rkMEYK",
        "outputId": "eac347e1-2825-4fe0-f344-fa9e7a9e37fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 149ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "утренневт внадию бласоь слониы л дерьйиквыо нпчлрьвы вып\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Слово"
      ],
      "metadata": {
        "id": "KDwf2O-eNrwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train_data.txt', 'r', encoding='utf-8') as f:\n",
        "    texts = f.read()\n",
        "    texts = texts.replace('\\ufeff', '') # убираем первый невидимый символ"
      ],
      "metadata": {
        "id": "0D1407zkOgUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxWordsCount = 1000\n",
        "tokenizer = Tokenizer(num_words=maxWordsCount, filters='!–\"—#$%&amp;()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r«»',\n",
        "                       lower=True, split=' ', char_level=False)\n",
        "tokenizer.fit_on_texts([texts])"
      ],
      "metadata": {
        "id": "dFadmK_lOjX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dist = list(tokenizer.word_counts.items())\n",
        "print(dist[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozJlSixkO8_o",
        "outputId": "b3c1d6ae-91f0-401d-e820-ef5e4b6286bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('вы', 3), ('лучший', 1), ('ответ', 1), ('на', 1), ('проблемы', 1), ('которые', 1), ('возникли', 1), ('в', 3), ('понедельник', 2), ('думайте', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = tokenizer.texts_to_sequences([texts])"
      ],
      "metadata": {
        "id": "rEOm9iHOPFQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = keras.utils.to_categorical(data[0], num_classes=maxWordsCount)\n",
        "print( dres.shape )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWhubBPMPL2p",
        "outputId": "02d23d7e-8c47-4354-dd80-b16f916eb8ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp_words = 3\n",
        "n = res.shape[0]-inp_words\n",
        "\n"
      ],
      "metadata": {
        "id": "CcaHGpF-QKgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([res[i:i+inp_words, :] for i in range(n)])\n",
        "Y = res[inp_words:]"
      ],
      "metadata": {
        "id": "4BMIftElQMlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Input((inp_words, maxWordsCount)))\n",
        "model.add(SimpleRNN(128, activation='tanh'))\n",
        "model.add(Dense(maxWordsCount, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9cT3YvEQOXy",
        "outputId": "57f305a9-44e3-4d9a-b176-6e8c39d59f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_25 (SimpleRNN)   (None, 128)               144512    \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1000)              129000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 273512 (1.04 MB)\n",
            "Trainable params: 273512 (1.04 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, Y, batch_size=32, epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1B80vSnQVXJ",
        "outputId": "ce5338b5-6b4f-42aa-e081-f5850ad55039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1/1 [==============================] - 1s 1s/step - loss: 6.8991 - accuracy: 0.0000e+00\n",
            "Epoch 2/15\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.8728 - accuracy: 0.0000e+00\n",
            "Epoch 3/15\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 6.8462 - accuracy: 0.0000e+00\n",
            "Epoch 4/15\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.8189 - accuracy: 0.0714\n",
            "Epoch 5/15\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.7908 - accuracy: 0.4286\n",
            "Epoch 6/15\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.7615 - accuracy: 0.9286\n",
            "Epoch 7/15\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.7307 - accuracy: 0.9643\n",
            "Epoch 8/15\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.6981 - accuracy: 1.0000\n",
            "Epoch 9/15\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.6634 - accuracy: 1.0000\n",
            "Epoch 10/15\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.6260 - accuracy: 1.0000\n",
            "Epoch 11/15\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.5856 - accuracy: 1.0000\n",
            "Epoch 12/15\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.5415 - accuracy: 1.0000\n",
            "Epoch 13/15\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.4930 - accuracy: 1.0000\n",
            "Epoch 14/15\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.4395 - accuracy: 1.0000\n",
            "Epoch 15/15\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.3800 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_QzN7VKsQrUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def buildPhrase(texts, str_len = 22):\n",
        "  res = texts\n",
        "  data = tokenizer.texts_to_sequences([texts])[0]\n",
        "  for i in range(str_len):\n",
        "    x = keras.utils.to_categorical(data[i: i+inp_words], num_classes=maxWordsCount) # преобразуем в One-Hot-encoding\n",
        "    inp = x.reshape(1, inp_words, maxWordsCount)\n",
        "\n",
        "    pred = model.predict( inp ) # предсказываем OHE четвертого символа\n",
        "    indx = pred.argmax(axis=1)[0]\n",
        "    data.append(indx)\n",
        "\n",
        "    res += \" \" + tokenizer.index_word[indx] # дописываем строку\n",
        "\n",
        "  return res"
      ],
      "metadata": {
        "id": "D048NiKDQaqx"
      },
      "execution_count": 435,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = buildPhrase(\"лучший ответ на\")\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOYiTdbIQshx",
        "outputId": "7e9c1122-252f-467f-d387-e2d262d52f52"
      },
      "execution_count": 436,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "лучший ответ на проблемы которые возникли в понедельник думайте позитивно и верьте в свою способность достигать отличных результатов если вы смогли в понедельник подняться с\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def buildPhrase(texts, model, tokenizer, inp_words=3, str_len=19):\n",
        "    res = texts\n",
        "    data = tokenizer.texts_to_sequences([texts])[0]\n",
        "\n",
        "    # Дополним данные до нужной длины\n",
        "    data = pad_sequences([data], maxlen=inp_words, padding='pre')[0]\n",
        "\n",
        "    for i in range(str_len):\n",
        "        x = keras.utils.to_categorical(data[-inp_words:], num_classes=maxWordsCount)\n",
        "        inp = x.reshape(1, inp_words, maxWordsCount)\n",
        "\n",
        "        pred = model.predict(inp)\n",
        "        indx = pred.argmax(axis=1)[0]\n",
        "        data = np.append(data, indx)\n",
        "\n",
        "        res += \" \" + tokenizer.index_word[indx]\n",
        "\n",
        "    return res\n",
        "\n"
      ],
      "metadata": {
        "id": "4Ge-pPdtYcVC"
      },
      "execution_count": 437,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Используем вашу модель model и tokenizer\n",
        "res = buildPhrase(\"позитив добавляет годы\", model, tokenizer)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqDuWl7DfZVN",
        "outputId": "bc77d583-2a6c-4087-f140-514ddb3d63e7"
      },
      "execution_count": 438,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "позитив добавляет годы верьте в свою способность достигать отличных результатов если вы смогли в понедельник подняться с постели значит вы супер герой\n"
          ]
        }
      ]
    }
  ]
}